---
title: "HT 7. Maquinas Vectoriales de Soporte(SVM)"
author: "Juan De Leon, Maria Jose Castro, Jose Block"
date: "20/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analisis
En esta HDT se trabajara con el modelo svm de la librería e1071  y varias otras funciónes que requieren transformaciónes de data. Primero se nos pide que se genere una variable que defina entre economico, caro e intermedio que ya se había hecho en hojas de trabajo pasadas. Dado que los datos máximos atípicos afectan considerablemente a una predicción, no se categorizan entre ninguna de las tres clasificaciónes por lo que se producen valores NA en nuestra variable tipoDeCasa. Para solventar este problema, eliminaremos las filas que tienen NA en la variable tipoDeCasa. Tambien es importante que las variables cuantitativas no tengan NA en ellas, por lo que las cambiamos por 0 tomando en cuenta lo que representa cada variable.
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(e1071)
library(caret)
library(corrplot)
library(labelled)
library(plotly)
library(ggplot2)
# Load Data
set.seed(123)
df = read.csv("./train.csv")
df[is.na(df)] <- 0
df$tipoDeCasa = as.numeric(as.character( cut(df$SalePrice,c(0,145000,205000,410000), labels = c(1, 2, 3))))
df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)],as.factor)
#Para borrar filas que tengan NA en una columna en especifico.
#https://stackoverflow.com/questions/11254524/omit-rows-containing-specific-column-of-na
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}
df <- completeFun(df, "tipoDeCasa")
str(df)
#X1stFlrSF      col#44
#BsmtFullBath   col#48
#TotRmsAbvGrd   col#55
#X2ndFlrSF      col#45
#GrLivArea      col#47
#GarageArea     col#63

#Separo datos con factor level > 2
frstselect <- df[,c(2:5,8,9,11:43,46,49:54,56:62,64:72,76:80,82)]

#Separo datos cuantitativos
scndselect <- subset (df, select = c(2,4,5,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,82))
scndselect[is.na(scndselect)] <- 0
```
Vamos a hacer un analisis de correlación, para descartar las variables cuantitativas que tienen mucha correlación entre ellas y así facilitar la fase del modelo. Para esto, se decidió separar la base de datos en dos conjuntos de datos, ya que son muchas columnas. La primer matriz hace referencia al conjunto1, la segunda hace referencia al conjunto2, la tercera es la matriz de correlación entre conjunto1 y conjunto2. Por último tenemos una tabla comparativa que nos permite ver con mayor facilidad la correlación entre la variable tipoDeCasa y todas las demás.
```{r echo=FALSE, message=FALSE, warning=FALSE}
#Correlacion
M <- cor(scndselect[,c(1:18)])
M1<- cor(scndselect[,c(19:37)])
M2<- cor(scndselect[,c(1:18)],scndselect[,c(19:37)])

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = FALSE)
corrplot(M1,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = FALSE)
corrplot(M2,  method = "color", col = col(200), order = "hclust", number.cex = .5,
         addCoef.col = "black",
         tl.col = "black",
         sig.level = 0.50, insig = "blank", 
         diag = TRUE)

tipocor<- cor(scndselect[,-1],scndselect$tipoDeCasa)
tipocor
```
Basandonos en la gráfica de correlación y el cuadro de correlación, las variables con mayor correlación con la variable tipoDeCasa son:

- OverallQual (cuantitativa)
- GarageCars  (cuantitativa)

Tambien sabemos que las variables que tienen una correlación entre ellas mayor a 0.6 son:

- TotalBsmtSF con X1stFlrSF 
- BsmtFinSF1 con BsmtFullBath
- X2ndFlrSF con GrLivArea con HalfBath con TotRmsAbvGrd
- FullBath con GrLivArea
- GarageCars con GarageArea 
- BedroomAbvGr con TotRmsAbvGrd

A continuación se verifica la correlación con la variable tipoDeCasa y se quitan las variables con menor correlación entre los conjuntos que tenían correlacion mutua, por lo tanto sacaremos a las siguientes variables:

- X1stFlrSF
- BsmtFullBath
- TotRmsAbvGrd
- X2ndFlrSF
- GrLivArea
- GarageArea

## Modelo de SVM
Uno de los principales requisitos es que los "factors" sean de al menos 2 niveles para poder ser ingresados a la función de svm. En totala se realizarán nueve modelos de los cuales 3 son lineles, 3 son radiales y 3 son polinomiales. Se cambiaron factores como costo, gamma, degree y coef0 para tener diferentes combinaciones que nos dieran diferentes resultados y en base a cada coonvinación, se buscaron numeros que promovieran una mayor precisión en la predicción.
```{r echo=FALSE, message=FALSE, warning=FALSE}
#Variables a sacar:
#X1stFlrSF      col#44
#BsmtFullBath   col#48
#TotRmsAbvGrd   col#55
#X2ndFlrSF      col#45
#GrLivArea      col#47
#GarageArea     col#63

# Select train y test
porciento <- 70/100
#Con todo tipo de variable
trainRowsNumber<-sample(1:nrow(frstselect),porciento*nrow(frstselect))
train<-frstselect[trainRowsNumber,]
test<-frstselect[-trainRowsNumber,]

#Con variables cuantitativas
trainRowsNum<-sample(1:nrow(scndselect),porciento*nrow(scndselect))
train1<-scndselect[trainRowsNum,]
test1<-scndselect[-trainRowsNum,]

#Modelos

modeloSVM_L1<-svm(tipoDeCasa~., data=train,type="C-classification", cost=2^5, kernel="linear") 
modeloSVM_L2<-svm(tipoDeCasa~., data=train,type="C-classification", cost=0.5, kernel="linear")
modeloSVM_L3<-svm(tipoDeCasa~., data=train,type="C-classification", cost=2^-5, kernel="linear")

modeloSVM_R1<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=0.005,kernel="radial")
modeloSVM_R2<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=0.05,kernel="radial")
modeloSVM_R3<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=2^-5,kernel="radial")

modeloSVM_P1<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=1, kernel="polynomial", coef0=1, degree= 8) 
modeloSVM_P2<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=5, kernel="polynomial", coef0=1)
modeloSVM_P3<-svm(tipoDeCasa~., data=train,type="C-classification", gamma=2^-5, kernel="polynomial", coef0=1)

summary(modeloSVM_L1)
summary(modeloSVM_R1)
summary(modeloSVM_P1)

#Predicciones
prediccionL1<-predict(modeloSVM_L1,newdata=test[,1:67])
prediccionL2<-predict(modeloSVM_L2,newdata=test[,1:67])
prediccionL3<-predict(modeloSVM_L3,newdata=test[,1:67])
prediccionR1<-predict(modeloSVM_R1,newdata=test[,1:67])#[,1:37]
prediccionR2<-predict(modeloSVM_R2,newdata=test[,1:67])#[,1:37]
prediccionR3<-predict(modeloSVM_R3,newdata=test[,1:67])#[,1:37]
prediccionP1<-predict(modeloSVM_P1,newdata=test[,1:67])
prediccionP2<-predict(modeloSVM_P2,newdata=test[,1:67])
prediccionP3<-predict(modeloSVM_P3,newdata=test[,1:67])

#Cambio de tipo de data a factors
test$tipoDeCasa<- as.factor(test$tipoDeCasa)
test1$tipoDeCasa<- as.factor(test$tipoDeCasa)

#Matrices de confusion
```

## Matrices de confusión:
Para esta parte hay que asegurar que ambos factores que se van a comparar que en este caso es predicción y test, es requerido que sean factores del mismo nivel, por lo que no puede haber ninún tipo de fallo en el formato de ambos factores. A continuación se pueden ver los resultados de los 9 modelos que se realizaron.

#### - Matrices de confusión de modelos lineales
```{r echo=FALSE, message=FALSE, warning=FALSE}
cmL1<-confusionMatrix(test$tipoDeCasa,prediccionL1)
cmL2<-confusionMatrix(test$tipoDeCasa,prediccionL2)
cmL3<-confusionMatrix(test$tipoDeCasa,prediccionL3)
cmL1
cmL2
cmL3
```

#### - Matrices de confusión de modelos radiales 
```{r echo=FALSE, message=FALSE, warning=FALSE}
cmR1<-confusionMatrix(test$tipoDeCasa,prediccionR1)
cmR2<-confusionMatrix(test$tipoDeCasa,prediccionR2)
cmR3<-confusionMatrix(test$tipoDeCasa,prediccionR3)
cmR1
cmR2
cmR3
```

#### - Matrices de confusión de modelos polinomiales 
```{r echo=FALSE, message=FALSE, warning=FALSE}
cmP1<-confusionMatrix(test$tipoDeCasa,prediccionP1)
cmP2<-confusionMatrix(test$tipoDeCasa,prediccionP2)
cmP3<-confusionMatrix(test$tipoDeCasa,prediccionP3)
cmP1
cmP2
cmP3
#Obtener accuracy de cada una
cmL1<-cmL1$overall[['Accuracy']]*100
cmL2<-cmL2$overall[['Accuracy']]*100
cmL3<-cmL3$overall[['Accuracy']]*100
cmR1<-cmR1$overall[['Accuracy']]*100
cmR2<-cmR2$overall[['Accuracy']]*100
cmR3<-cmR3$overall[['Accuracy']]*100
cmP1<-cmP1$overall[['Accuracy']]*100
cmP2<-cmP2$overall[['Accuracy']]*100
cmP3<-cmP3$overall[['Accuracy']]*100
accuracycm1<- c(cmL1,cmR1,cmP1)
accuracycm2<- c(cmL2,cmR2,cmP2)
accuracycm3<- c(cmL3,cmR3,cmP3)
tiposvmcm<- c("linear","radial","polinomial")
accuracycm4<- c(cmL1,cmL2,cmL3)
accuracycm5<- c(cmR1,cmR2,cmR3)
accuracycm6<- c(cmP1,cmP2,cmP3)
data <- data.frame(tiposvmcm, accuracycm1, accuracycm2, accuracycm3)
```

- En la siguiente gráfica se puede apreciar la comparación entre presiciones de los nueve modelos que se realizaron, agrupados por tipo de kernel. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
fig <- plot_ly(data, x = ~tiposvmcm, y = ~accuracycm1, type = 'bar', name = '')
fig <- fig %>% add_trace(y = ~accuracycm2, name = '')
fig <- fig %>% add_trace(y = ~accuracycm3, name = '')
fig <- fig %>% layout(title="(Accuracy vs kernel type) of SVM",yaxis = list(title = 'Accuracy(%)'),xaxis = list(title = 'kernel'), barmode = 'group')
fig
```

