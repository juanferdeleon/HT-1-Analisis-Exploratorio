---
title: "HT 5. Naive Bayes"
author: "Juan De Leon, Maria Jose Castro, Jose Block"
date: "28/03/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## - Naive Bayes 

```{r echo=FALSE, warning=FALSE}
library(e1071)
library(caret)
# Load Data
df = read.csv("./train.csv")
df$tipoDeCasa = as.numeric(as.character( cut(df$SalePrice,c(0,145000,205000,410000), labels = c(1, 2, 3))))

# Select Data
porciento <- 70/100
frstselect <- subset (df, select = -c(1,81))
trainRowsNumber<-sample(1:nrow(frstselect),porciento*nrow(frstselect))
train<-frstselect[trainRowsNumber,]
test<-frstselect[-trainRowsNumber,]

# Modelo de Naive Bayes
train$tipoDeCasa <- factor(train$tipoDeCasa)
modelo<-naiveBayes(train$tipoDeCasa~., data=train)
```
A continuacion se puede ver el modelo dado por Naive Bayes:
```{r echo=FALSE, warning=FALSE }
modelo
predBayes<-predict(modelo, newdata = test)
```
Un resumen de los resultados de la prediccion de Naive Bayes:
```{r echo=FALSE, warning=FALSE }
summary(predBayes)
```
Matriz de confusion:
```{r echo=FALSE, warning=FALSE }
cm<-confusionMatrix(predBayes,factor(test$tipoDeCasa))
cm
```
Con el uso de todas las variables de la base de datos,se pudo obtener el modelo de Naive Bayes. Se hizo la prediccion y segun la matriz de confusion, tiene una precision entre 65% y 75%. En este caso se uso el 70% delos datos como grupo de entrenamiento para mantener el mismo en todos los modelos antes trabajados. Sugerimos aumentar la cantidad de datos o en este caso el porcentaje, para tener una prediccion mas precisa. A continuacion se da una muestra con un 80% de grupo de entrenamiento.

```{r echo=FALSE, warning=FALSE}
# Select Data
porcentaje <- 80/100
frstselect <- subset (df, select = -c(1,81))
trainRowsNum<-sample(1:nrow(frstselect),porcentaje*nrow(frstselect))
train2<-frstselect[trainRowsNum,]
test2<-frstselect[-trainRowsNum,]

# Modelo de Naive Bayes
train2$tipoDeCasa <- factor(train2$tipoDeCasa)
modelo2<-naiveBayes(train2$tipoDeCasa~., data=train2)
```
A continuacion se puede ver el modelo dado por Naive Bayes:
```{r echo=FALSE, warning=FALSE }
predBayes2<-predict(modelo2, newdata = test2)
```
Un resumen de los resultados de la prediccion de Naive Bayes:
```{r echo=FALSE, warning=FALSE }
summary(predBayes2)
```
Matriz de confusion:
```{r echo=FALSE, warning=FALSE }
cm2<-confusionMatrix(predBayes2,factor(test2$tipoDeCasa))
cm2
```
Los resultados son bastante parecidos a pesar de ser 80% de entrenamiento, hay corridas en las que sale victorioso el 70% de entrenamiento.

### Cross Validation

```{r echo=FALSE, include=FALSE }

library(h2o)
library(dplyr)

# start up h2o
h2o.no_progress()
h2o.init()

# create feature names
y <- "tipoDeCasa"
x <- setdiff(names(train2), y)

# h2o cannot ingest ordered factors
train2.h2o <- train2 %>%
  mutate_if(is.factor, factor, ordered = FALSE) %>%
  as.h2o()

# train model
nb.h2o <- h2o.naiveBayes(
  x = x,
  y = y,
  training_frame = train2.h2o,
  nfolds = 10,
  laplace = 0
)

# assess results
confusionMatrixCrossValidationTrain <- h2o.confusionMatrix(nb.h2o)


```

#### - Matriz de Validacion Cruzada

Aqui podemos apreciar la matriz de confusion del conjunto de datos de entrenamiento para la validacion cruzada.

```{r}
confusionMatrixCrossValidationTrain
```

Luego pasamos al conjunto de prueba.

```{r echo=FALSE, include=FALSE}

# do a little preprocessing
preprocess <- preProcess(train2, method = c("BoxCox", "center", "scale"))
train_pp   <- predict(preprocess, train2)
test_pp    <- predict(preprocess, test2)

# convert to h2o objects
train_pp.h2o <- train_pp %>%
  mutate_if(is.factor, factor, ordered = FALSE) %>%
  as.h2o()

test_pp.h2o <- test_pp %>%
  mutate_if(is.factor, factor, ordered = FALSE) %>%
  as.h2o()

# get new feature names --> PCA preprocessing reduced and changed some features
x <- setdiff(names(train_pp), "tipoDeCasa")


# create tuning grid
hyper_params <- list(
  laplace = seq(0, 5, by = 0.5)
  )

# build grid search 
grid <- h2o.grid(
  algorithm = "naivebayes",
  grid_id = "nb_grid",
  x = x, 
  y = y, 
  training_frame = train_pp.h2o, 
  nfolds = 10,
  hyper_params = hyper_params
  )

# Sort the grid models by mse
sorted_grid <- h2o.getGrid("nb_grid", sort_by = "accuracy", decreasing = TRUE)

# grab top model id
best_h2o_model <- sorted_grid@model_ids[[1]]
best_model <- h2o.getModel(best_h2o_model)

# confusion matrix of best model
confusionMatrixCrossValidationTest <- h2o.confusionMatrix(best_model)

```

```{r}
confusionMatrixCrossValidationTest
```

Finalmente evaluamos la eficiancia del algoritmo.

```{r}
# evaluate on test set
h2o.performance(best_model, newdata = test_pp.h2o)
```

Debajo podemos apreciar los el set de datos de prueba y las predicciones que el algoritmo brindo para cada 1.

```{r}
# predict new data
predict <- h2o.predict(nb.h2o, newdata = test_pp.h2o)
predict
```

```{r include=FALSE, echo=FALSE}
# shut down h2o
h2o.shutdown(prompt = FALSE)


```
