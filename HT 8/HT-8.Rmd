---
title: "HT-8"
author: "Juan De Leon, Maria Jose Castro, Jose Block"
date: "4/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analisis

En esta hoja de trabajo se generaran dos modelos de redes neuronales que sean capaces de clasificar usando la variable de respuesta que categoriza las casas en baratas, medias y caras. Estos modelos tendran diferentes topologias y funciones de activacion. Estos modelos se utilizaran para predecir la variable de respuesta. Asimismo, se realizaran las matrices de confucion y se compararan los resultados. Seguido de esto, se realizara el mismo proceso pero para la variable SalesPrice, de manera que el algoritmo prediga el precio de las casas. 

```{r echo=FALSE, warning=FALSE, include=FALSE}
# Librerias
library(caret)
library(nnet)
library(RWeka)
library(neural)
library(dummy)
library(neuralnet)
library(plotly)
library(MASS)
library(neuralnet)
library(ggplot2)
library(PerformanceAnalytics)
```

## Variable de Respuesta "tipoDeCasa"

### Red Neuronal con caret

A continuacion se muestra el modelo generado con caret: 

```{r echo=FALSE, warning=FALSE, include=FALSE}
#Obtención de datos
datos = read.csv("./train.csv")
set.seed(123)

#División de 3 cosas
datos[is.na(datos)] <- 0
datos$tipoDeCasa = as.numeric(as.character( cut(datos$SalePrice,c(0,145000,205000,410000), labels = c(1, 2, 3))))

#Para borrar filas que tengan NA en una columna en especifico.
#https://stackoverflow.com/questions/11254524/omit-rows-containing-specific-column-of-na
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}
datos <- completeFun(datos, "tipoDeCasa")

#Separo datos cuantitativos
scndselect <- subset(datos, select = c(2,4,5,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78, 81, 82))
scndselect[is.na(scndselect)] <- 0
```

```{r echo=FALSE, warning=FALSE, include=FALSE}
# Red Neuronal con caret

porcentaje<-0.7
corte <- sample(nrow(scndselect),nrow(scndselect)*porcentaje)
train<-scndselect[corte,]
test<-scndselect[-corte,]

modeloCaret <- train(tipoDeCasa~., data=train, method="nnet",preProcess=c("scale","center"), na.action = na.omit, linout = TRUE)# Por defecto el modelo usa la funcion de activacion sigmoide
```

```{r echo=FALSE}
modeloCaret
```

Seguido de esto vemos la prediccion y su matriz de confusion:

```{r echo=FALSE, warning=FALSE}
test$prediccionCaret <- predict(modeloCaret, newdata = test)
test$prediccionCaret[] <- round(test$prediccionCaret, digits = 0)
u <- union(test$prediccionCaret,test$tipoDeCasa)
t <- table(factor(test$prediccionCaret, u), factor(test$tipoDeCasa, u))
cfmCaret<-confusionMatrix(t)
cfmCaret
```

### Red Neuronal con NNet

A continuacion se muestra el modelo generado con NNet: 

```{r echo=FALSE}
# Red Neuronal con NNet
modelo.nn2 <- nnet(tipoDeCasa~.,data = scndselect,subset = corte, size=25, rang=0.1, decay=5e-4, maxit=300, linout = TRUE)# por defecto el modelo utiliza la funcion de activacion logistica
prediccion2 <- round(predict(modelo.nn2, newdata = test[,1:37]))
```

Seguido de esto vemos la prediccion y su matriz de confusion:

```{r echo=FALSE}

test$prediccion2<-prediccion2 #Se le añade al grupo de prueba el valor de la predicción
u <- union(test$prediccion2,test$tipoDeCasa)
t <- table(factor(test$prediccion2, u), factor(test$tipoDeCasa, u))
cfm<-confusionMatrix(t)
cfm
```

### Comparacion de Resultados con otros modelos de clasificacion

#### Matríz de confusión Naive Bayes 
![](./NaiveBayes.PNG)

#### Matríz de confusión Regression Lineal
![](./LinearRegression.PNG)

#### Matríz de confusión Arbol de Clasificación 
![](./ClassificationTree.PNG)

#### Matríz de confusión SVM
- Modelos Lineales
![](./CMModelosLineales.PNG)
- Modelos Radiales
![](./CMModelosRadiales.PNG)
- Modelos Polinomiales
![](./CMModelosPolinomiales.PNG)

Debajo tenemos una grafica comparativa del Accuracy obtenido de los modelos utilizados para las predicciones:

```{r echo=FALSE}
modelos_prediccion <- c("Naive Bayes", "Regresion Lineal", "Arbol de Clasificacion", "SVM", "Neural Net(Caret)", "Neural Net(NNet)")
accuracies <- c(76.69, 70.05, 73.61, 83.99, 85.85, 85.61)

comparacion_prediccion <- data.frame(modelos_prediccion, accuracies)

fig_1 <- plot_ly(comparacion_prediccion, x = ~modelos_prediccion, y = ~accuracies, type = 'bar', text = paste(signif(accuracies,digits = 4),"%"), textposition = 'auto', name = '')
fig_1<- fig_1 %>% layout(title="Precision del modelo vs Modelo Aplicado",yaxis = list(title = 'Accuracy(%)'),xaxis = list(title = 'Modelo Aplicado'), barmode = 'group')

fig_1
```

## Variable de Respuesta "SalePrice"

```{r echo=FALSE}
#normalizacion Min-Max de los datos
maxs      <- apply(train, 2, max)
mins      <- apply(train, 2, min)

datos_normalized <- as.data.frame(scale(scndselect, center = mins, scale = maxs - mins))
train_normalized <- datos_normalized[corte, ]
test_normalized  <- datos_normalized[-corte, ]

#modelo
modelo.nnet <- neuralnet(SalePrice~., data = train_normalized, hidden = c(7,5), threshold = 0.05, algorithm     = "rprop+")

#Prediccion
pr.nnet   <- compute(modelo.nnet,within(test_normalized,rm(SalePrice)))

#Se desnormaliza los valores
SalePrice.predict <- pr.nnet$net.result*(max(datos$SalePrice)-min(datos$SalePrice))+min(datos$SalePrice)
SalePrice.real    <- (test_normalized$SalePrice)*(max(datos$SalePrice)-min(datos$SalePrice))+min(datos$SalePrice)

# Calcular el accuracy individual mediante el error
SalePrice_predict_vs_real <- data.frame(SalePrice.predict, SalePrice.real)
SalePrice_predict_vs_real$accuracy <- 0
SalePrice_predict_vs_real$accuracy[] <- (1 - abs(SalePrice_predict_vs_real$SalePrice.real - SalePrice_predict_vs_real$SalePrice.predict)/SalePrice_predict_vs_real$SalePrice.real)*100

summary(SalePrice_predict_vs_real$accuracy)

```