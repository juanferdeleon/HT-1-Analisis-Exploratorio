---
title: "HT 4. Modelos de Regresion Lineal"
author: "Juan De Leon, Maria Jose Castro, Jose Block"
date: "22/03/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## - Modelo de Regresion Lineal 

```{r echo=FALSE, warning=FALSE}

# Load Data
df = read.csv("./train.csv")
df$tipoDeCasa = as.numeric(as.character( cut(df$SalePrice,c(0,145000,205000,410000), labels = c(1, 2, 3))))

# Check correlation
library(corrplot)
frstselect <- subset (df, select = c(2,4,5,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,82))
sapply(frstselect,class)
M <- cor(frstselect)
corrplot(M, method = "circle") # Display the correlation coefficient
```


Se escoge qué variables tienen una correlación evidente, por color.Por lo tanto se decide que las variables que tienen correlación entre ellas que hay que escoger una entre esas, serían las siguientes:

TotalBsmtSF con X1stFlrSF con X2ndFlrSF,
GrLivArea con TotRmsAbvGrd,
BsmtFinSF1 con BsmtFullBath,y 
OverallQual con GarageCars con GarageArea

A continuacion se puede ver la correlacion del las variables anteriormente mencionadas con SalePrice, a partir de estos resultados escogemos que variables entre las correlacionadas se escogeran como representante del resto.
```{r echo=FALSE, warning=FALSE }
#Compare correlation between chosen vars
compco <- subset (df, select = c(18,35,39,44,45,47,48,55,62,63))
cor(compco, df$SalePrice)
# Separate data
porciento <- 70/100
datoslm <- subset (df, select = c(2,4,5,18,19,20,21,27,35,37,38,39,46,47,49,50,51,52,53,57,60,67,68,69,70,71,72,76,77,78,82))
trainRowsNumber<-sample(1:nrow(datoslm),porciento*nrow(datoslm))
train<-datoslm[trainRowsNumber,]
test<-datoslm[-trainRowsNumber,]

# Save Info
save(train,test, file = "TrainTest.RData")

```

```{r echo=FALSE, warning=FALSE }

load("TrainTest.RData")

# Create Lineal Model
Model <- lm(tipoDeCasa ~ . , data = train)
```


A continuacion se tiene el Modelo lineal que se produjo de los datos cuantitativos:
```{r echo=FALSE, warning=FALSE }
Model

# Prediction
library(caret)
test$prediccion <- predict(Model, newdata = test)
testcomp <- subset (test, select = c(31,32))
testcomp = round(testcomp, digits = 0)
testcomp$prediccion = ifelse(testcomp$prediccion %in% c(1,2,3) ,testcomp$prediccion*1, 1)
testcomp = testcomp[rowSums(is.na(testcomp[ , 1:2])) == 0, ]
```


Luego se puede ver el tipo de data con la que vamos a trabajar y comprobar que esté en el formato correcto, con un summary().
```{r echo=FALSE, warning=FALSE }
sapply(testcomp, class)
summary(testcomp)
testfn <- table(testcomp)
```


Ahora la matriz de confusión que nos brinda información de la efectividad del modelo para predecir.
```{r echo=FALSE, warning=FALSE }
# Comparing Values
cfm<-confusionMatrix(testfn)
cfm

```

En los modelos de prediccion buscamos que las dos graficas presentadas anteriormente sean lo mas similar posible. 


## - Analisis del Modelo

En este caso podemos ver que el modelo de regresion lineal es posible indicar que la efectividad del mismo fue relativamente alta. Dado que hubieron unos datos atipicos en el set de datos este el modelo no fue exato en su totalidad, pero nos pudo brindar algo muy cercano a la realidad. Se puede decir que estos datos atipicos causan alteraciones en el Modelo de Prediccion.

## - Calidad, Eficiencia, Efectividad Y  del Modelo

En cuanto a la calidad del modelo debemos de comparar la calidad con las predicciones realizadas, para esto podemos ver la siguiente grafica.

```{r echo=FALSE, warning=FALSE }

plot(testcomp$tipoDeCasa, type="l", lty=1.8, col="blue")
lines(testcomp$prediccion, type="l", col="red")

# Finding Accuracy
#xrmse <- sqrt(mean(test$tipoDeCasa-testcomp$prediccion)^2)

```


Se puede apreciar en la grafica, la linea azul muestra el set de datos de test en el que se separaron los tipos de casas (Economicas, Intermedias y Caras). De igual manera lo hizo el algoritmo de prediccion, separó e identifico cuales casas eran Economicas, Intermedias y Caras en base del conjunto de test (linea roja en la grafica), lo cual nos permite decir que fue un algoritmo eficiente ya que si realizó la tarea exitosamente. Se puso una grafica sobre la otra para poder determinar si el algoritmo clasificó con exactitud el set de datos. Como podemos ver la similitud es bastante aproximada, por lo tanto podemos concluir que la calidad del modelo fue lo suficiente para asemejarse al conjunto original, es decir, fue efectivo.

Para poder aumentar la calidad en cuanto a los datos se puede igresar una mayor cantidad de informacion o reevaluar si se pueden tomar en cuenta mas variables para aumentar la calidad y la efectividad del modelo.


## - Eficiancia del Algoritmo VS Arbol de Desicion 

En este caso podemos ver que el algoritmo tuvo la misma accuracy que e arbol de desicion usado previamente pero podemos ver que el algoritmo logro esto mismo con una mejor cantidad de datos. 

En el algortimo tenemos que el nivel de  Accuracy : 0.7235, de igual manera que en el arbol.    

Por lo tanto podemos determinar que el algoritmo es eficiente. Queda abierto para poder saber si el uso de menos o mas variables podria hacer un cambio significativo en el nivel de accuracy obtenido por el algoritmo. 

El cambio esperado en la accuracy al tener mas variables podria ser de disminucion por la cantidad de datos e identificacion de patrones. 